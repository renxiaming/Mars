# Swin-Transformer YOLO Configuration - TEACHER Mode
# Train on first 10 classes for knowledge distillation

# Model Configuration
modelName: "swin"  # 使用Swin-Transformer模型
phase: "nano"
nc: 1  # number of classes (will be set by cfgops)
device: "cuda"
inputShape: [640, 640, 3]
regMax: 16

# Training Configuration - Teacher training
epochs: 200  # 教师模型完整训练
batchSize: 6  # 由于Swin-Transformer内存需求更高，使用较小batch size
learningRate: 0.01  # 标准学习率
momentum: 0.937
weightDecay: 0.0005
warmupEpochs: 3.0
warmupMomentum: 0.8
warmupBias: 0.1
boxGain: 7.5
clsGain: 0.5
dflGain: 1.5

# Data Configuration
datasetName: "marsDataset"
augmentation: True

# EMA Configuration
useEMA: True
emaDecay: 0.9999
emaWarmupEpochs: 3

# Swin-Transformer specific configs
swin:
  embed_dim: 96      # 基础embedding维度
  depths: [2, 2, 6, 2]  # 每个stage的block数量
  num_heads: [3, 6, 12, 24]  # 每个stage的注意力头数
  window_size: 7     # 窗口大小
  drop_path_rate: 0.1  # stochastic depth率
  
# Output Configuration - 独立保存目录
outputPath: "runs/swin_transformer_teacher"
modelSaveName: "swin_teacher_model"
saveWeights: True
saveBest: True

# Backbone Configuration
backboneUrl: null  # Swin不使用YOLO预训练权重

# Loss Configuration
lossWeights:
  box: 7.5
  cls: 0.5
  dfl: 1.5 